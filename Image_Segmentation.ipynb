{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Segmentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeep0412/Semantic-Segmentation-with-Spiking-Neural-Networks/blob/master/Image_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7sw36YHICo9",
        "colab_type": "code",
        "outputId": "ae122095-c576-4e09-aaca-a0c53dd2f90b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1183
        }
      },
      "source": [
        "!pip install nengo\n",
        "!pip install nengo_dl\n",
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nengo\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/ce/e314e1176bfbbe6c3b6cf4e8fa0620cafad8f8bad04203c55881e9cb2fb0/nengo-2.8.0-py2.py3-none-any.whl (375kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from nengo) (1.16.3)\n",
            "Installing collected packages: nengo\n",
            "Successfully installed nengo-2.8.0\n",
            "Collecting nengo_dl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/3d/657cdc1cfc5964a2635c26cc1f21857d51a1b065a12136cead36e9b7b599/nengo-dl-2.1.1.tar.gz (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: nengo>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from nengo_dl) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from nengo_dl) (1.16.3)\n",
            "Requirement already satisfied: tensorflow>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from nengo_dl) (1.13.1)\n",
            "Collecting progressbar2>=3.39.0 (from nengo_dl)\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/89/d90f9ff03285d8eb56994e8cec1b73a4d0dc9bb529c1f8e8e10b1b663843/progressbar2-3.39.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.4.0->nengo_dl) (1.13.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.4.0->nengo_dl) (0.7.1)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.4.0->nengo_dl) (1.13.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.4.0->nengo_dl) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.4.0->nengo_dl) (1.0.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.4.0->nengo_dl) (0.33.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.4.0->nengo_dl) (1.0.9)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.4.0->nengo_dl) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.4.0->nengo_dl) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.4.0->nengo_dl) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.4.0->nengo_dl) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.4.0->nengo_dl) (1.12.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2>=3.39.0->nengo_dl) (2.3.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow>=1.4.0->nengo_dl) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow>=1.4.0->nengo_dl) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow>=1.4.0->nengo_dl) (0.15.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow>=1.4.0->nengo_dl) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=1.4.0->nengo_dl) (41.0.1)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow>=1.4.0->nengo_dl) (5.2.0)\n",
            "Building wheels for collected packages: nengo-dl\n",
            "  Building wheel for nengo-dl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/54/f4/02b8c2eb19045bb527c4a07edbcc1719b6475d1b4b0ecdc084\n",
            "Successfully built nengo-dl\n",
            "Installing collected packages: progressbar2, nengo-dl\n",
            "  Found existing installation: progressbar2 3.38.0\n",
            "    Uninstalling progressbar2-3.38.0:\n",
            "      Successfully uninstalled progressbar2-3.38.0\n",
            "Successfully installed nengo-dl-2.1.1 progressbar2-3.39.3\n",
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 54kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.16.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.9)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (41.0.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (3.1)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (5.2.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RohpjlZHHJQ_",
        "colab_type": "code",
        "outputId": "021613fe-575b-4c80-f86f-699d65c88661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import sys\n",
        "import os\n",
        "from urllib.request import urlopen\n",
        "import io\n",
        "import shutil\n",
        "import stat\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow.contrib.slim as slim;\n",
        "\n",
        "import nengo\n",
        "import nengo_dl\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "from pylab import *\n",
        "import os\n",
        "import sys\n",
        "#from keras_contrib.applications import densenet\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.python.keras.engine import Layer\n",
        "from tensorflow.keras.applications.vgg16 import *\n",
        "from tensorflow.keras.models import *\n",
        "#from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.preprocessing import image\n",
        "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "#from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOWmAgtPuFIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_images_bilinear(X, height_factor=1, width_factor=1, target_height=None, target_width=None, data_format='default'):\n",
        "    if data_format == 'default':\n",
        "        data_format = K.image_data_format()\n",
        "    if data_format == 'channels_first':\n",
        "        original_shape = K.int_shape(X)\n",
        "        if target_height and target_width:\n",
        "            new_shape = tf.constant(np.array((target_height, target_width)).astype('int32'))\n",
        "        else:\n",
        "            new_shape = tf.shape(X)[2:]\n",
        "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n",
        "        X = permute_dimensions(X, [0, 2, 3, 1])\n",
        "        X = tf.image.resize_bilinear(X, new_shape)\n",
        "        X = permute_dimensions(X, [0, 3, 1, 2])\n",
        "        if target_height and target_width:\n",
        "            X.set_shape((None, None, target_height, target_width))\n",
        "        else:\n",
        "            X.set_shape((None, None, original_shape[2] * height_factor, original_shape[3] * width_factor))\n",
        "        return X\n",
        "    elif data_format == 'channels_last':\n",
        "        original_shape = K.int_shape(X)\n",
        "        if target_height and target_width:\n",
        "            new_shape = tf.constant(np.array((target_height, target_width)).astype('int32'))\n",
        "        else:\n",
        "            new_shape = tf.shape(X)[1:3]\n",
        "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n",
        "        X = tf.image.resize_bilinear(X, new_shape)\n",
        "        if target_height and target_width:\n",
        "            X.set_shape((None, target_height, target_width, None))\n",
        "        else:\n",
        "            X.set_shape((None, original_shape[1] * height_factor, original_shape[2] * width_factor, None))\n",
        "        return X\n",
        "    else:\n",
        "        raise Exception('Invalid data_format: ' + data_format)\n",
        "\n",
        "class BilinearUpSampling2D(Layer):\n",
        "    def __init__(self, size=(1, 1), target_size=None, data_format='default', **kwargs):\n",
        "        if data_format == 'default':\n",
        "            data_format = K.image_data_format()\n",
        "        self.size = tuple(size)\n",
        "        if target_size is not None:\n",
        "            self.target_size = tuple(target_size)\n",
        "        else:\n",
        "            self.target_size = None\n",
        "        assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {tf, th}'\n",
        "        self.data_format = data_format\n",
        "        self.input_spec = [InputSpec(ndim=4)]\n",
        "        super(BilinearUpSampling2D, self).__init__(**kwargs)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            width = int(self.size[0] * input_shape[2] if input_shape[2] is not None else None)\n",
        "            height = int(self.size[1] * input_shape[3] if input_shape[3] is not None else None)\n",
        "            if self.target_size is not None:\n",
        "                width = self.target_size[0]\n",
        "                height = self.target_size[1]\n",
        "            return (input_shape[0],\n",
        "                    input_shape[1],\n",
        "                    width,\n",
        "                    height)\n",
        "        elif self.data_format == 'channels_last':\n",
        "            width = int(self.size[0] * input_shape[1] if input_shape[1] is not None else None)\n",
        "            height = int(self.size[1] * input_shape[2] if input_shape[2] is not None else None)\n",
        "            if self.target_size is not None:\n",
        "                width = self.target_size[0]\n",
        "                height = self.target_size[1]\n",
        "            return (input_shape[0],\n",
        "                    width,\n",
        "                    height,\n",
        "                    input_shape[3])\n",
        "        else:\n",
        "            raise Exception('Invalid data_format: ' + self.data_format)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        if self.target_size is not None:\n",
        "            return resize_images_bilinear(x, target_height=self.target_size[0], target_width=self.target_size[1], data_format=self.data_format)\n",
        "        else:\n",
        "            return resize_images_bilinear(x, height_factor=self.size[0], width_factor=self.size[1], data_format=self.data_format)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'size': self.size, 'target_size': self.target_size}\n",
        "        base_config = super(BilinearUpSampling2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA9ldOevK0gE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def FCN_Vgg16_32s(input_shape=(640, 640, 3), weight_decay=0., batch_momentum=0.9, batch_shape=(1,) + (640,640) + (3, ), classes=12):\n",
        "    #x = x1.flatten()\n",
        "    if batch_shape:\n",
        "        img_input = Input(batch_shape=batch_shape)\n",
        "        image_size = batch_shape[1:3]\n",
        "        print(\"x\", img_input)\n",
        "        print(\"y\", image_size)\n",
        "    else:\n",
        "        img_input = Input(shape=input_shape)\n",
        "        #img_input = \"/content/drive/My Drive/Colab Notebooks/img1.jpeg\"\n",
        "        image_size = input_shape[0:2]\n",
        "        print(\"x\", img_input)\n",
        "        print(\"y\", image_size)\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', kernel_regularizer=l2(weight_decay))(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "    # Convolutional layers transfered from fully-connected layers\n",
        "    x = Conv2D(4096, (7, 7), activation='relu', padding='same', name='fc1', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Conv2D(4096, (1, 1), activation='relu', padding='same', name='fc2', kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    \n",
        "    #classifying layer\n",
        "    x = Conv2D(classes, (1, 1), kernel_initializer='he_normal', activation='linear', padding='valid', strides=(1, 1), kernel_regularizer=l2(weight_decay))(x)\n",
        "\n",
        "    x = BilinearUpSampling2D(size=(32, 32))(x)\n",
        "    #print(x)\n",
        "    #x = .add(Dense(10, activation='softmax'))\n",
        "    #x = tf.keras.layers.Dense((tf.math.argmax(tf.Variable(x), dimension=3, name=\"Pred\")))(x)\n",
        "    #x = np.argmax(np.squeeze(x), axis=-1).astype(np.uint8)\n",
        "    #x = keras.layers.Dense(1)(x)\n",
        "    #x = tf.keras.backend.argmax(x, axis=-1)\n",
        "    #x = (lambda y : K.argmax(y, axis=-1))(x)\n",
        "    x = Flatten()(x)\n",
        "    model = Model(img_input,x)\n",
        "    #weights_path = os.path.expanduser(os.path.join('~', '.keras/models/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5'))\n",
        "    #model.load_weights(weights_path, by_name=True)\n",
        "    #print(model.summary())\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkfCnYR-HH1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_list = [\"/content/drive/My Drive/Colab Notebooks/img1.jpg\"]\n",
        "def preprocess_img(img):\n",
        "    x = image.load_img(img, target_size=(640,640))\n",
        "    x = image.img_to_array(x)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iOwDMpuIaes",
        "colab_type": "code",
        "outputId": "e9bc3e95-38e5-4fce-a138-84e37fd287d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "#Create Keras Model - Already defined in Keras. Train in nengo_dl\n",
        "image_shape = (640, 640)\n",
        "\n",
        "model = FCN_Vgg16_32s()\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_weights = \"/content/drive/My Drive/Colab Notebooks/apc_weights.hdf5\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x Tensor(\"input_1:0\", shape=(1, 640, 640, 3), dtype=float32)\n",
            "y (640, 640)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-bqU8gSIjut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KerasNode:\n",
        "    def __init__(self, keras_model):\n",
        "        self.model = keras_model\n",
        "\n",
        "    def pre_build(self, *args):\n",
        "        self.model = keras.models.clone_model(self.model)\n",
        "\n",
        "    def __call__(self, t, x):\n",
        "        images = tf.reshape(x, (-1,) + image_shape)\n",
        "        print(images)\n",
        "        return self.model.call(images)\n",
        "\n",
        "    def post_build(self, sess, rng):\n",
        "        self.model.load_weights(model_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUwRqhaDIrXy",
        "colab_type": "code",
        "outputId": "4cf82312-e702-43c3-b1f2-079ebaca7853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "#CREATE TENSOR NODE\n",
        "class_names = ['background','crayola_24_ct','expo_dry_erase_board_eraser','folgers_classic_roast_coffee','scotch_duct_tape','up_glucose_bottle','laugh_out_loud_joke_book','soft_white_lightbulb','kleenex_tissue_box','dove_beauty_bar','elmers_washable_no_run_school_glue','rawlings_baseball']\n",
        "num_classes = 4915200\n",
        "image_shape = (640,640,3)\n",
        "net_input_shape = np.prod(image_shape)\n",
        "for x in train_list:\n",
        "    x = preprocess_img(x)\n",
        "    with nengo.Network() as net:\n",
        "        input_node = nengo.Node(output = x.flatten())\n",
        "        keras_node = nengo_dl.TensorNode(KerasNode(model), size_in=net_input_shape, size_out = num_classes)\n",
        "        # connect up our input to our keras node\n",
        "        nengo.Connection(input_node, keras_node, synapse=None)\n",
        "        #nengo.Connection()\n",
        "        keras_p = nengo.Probe(keras_node)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ec8827547e7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnet_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnengo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minput_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnengo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-96089b551c98>\u001b[0m in \u001b[0;36mpreprocess_img\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Colab Notebooks/img1.jpg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    102\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    103\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/img1.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSC7-cy2ORhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_list = [\"/content/drive/My Drive/Colab Notebooks/img1.jpg\"]\n",
        "minibatch_size = 1\n",
        "np.random.seed(1)\n",
        "for i in test_list:\n",
        "    test_inputs = preprocess_img(i)\n",
        "    test_inputs = test_inputs.reshape((-1, net_input_shape))\n",
        "    test_inputs = test_inputs[:, None, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZe7Sg3qIxRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with nengo_dl.Simulator(net, minibatch_size=1) as sim:\n",
        "    sim.step(data={input_node:test_inputs})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHzyoGAFQVT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = image.load_img(\"/content/drive/My Drive/Colab Notebooks/img1.jpg\", target_size=(640,640))\n",
        "x1 = image.img_to_array(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JuUdMdRMdFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensornode_output = sim.data[keras_p]\n",
        "output = np.reshape(tensornode_output, [640,640,12])\n",
        "output = np.argmax(output, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPB2zTguaSQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_c =np.multiply(10,output)\n",
        "output_c = np.subtract(255,output_c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfTSEZmwakYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgplot = plt.imshow(output_c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdwIg7Upas8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = image.load_img(\"/content/drive/My Drive/Colab Notebooks/img1.jpg\", target_size=(640,640))\n",
        "x1 = image.img_to_array(img)\n",
        "plt.imshow(x1.astype(int))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}